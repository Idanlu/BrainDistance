{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f38f84-b1c5-4cb7-bb8c-af1aaf4c1274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FastSurfer.FastSurferCNN.data_loader.load_neuroimaging_data import load_and_conform_image\n",
    "import nibabel as nib\n",
    "from nibabel.processing import conform\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import ImageFilter\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchviz import make_dot\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "from models.densenet import densenet121\n",
    "\n",
    "from lime.lime_tabular import LimeTabularExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a828da-ebec-44d4-a34d-974df2f992e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Processing and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e0a6a-0a7a-43d5-b1e7-5a3acf937330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_csv('data/info.csv')\n",
    "\n",
    "ORDER_MAP = {'Artiodactyla':0,\n",
    " 'Carnivora':1,\n",
    " 'Chiroptera':2,\n",
    " 'Eulipotyphla':3,\n",
    " 'Hyracoidea':4,\n",
    " 'Lagomorpha':5,\n",
    " 'Marsupialia':6,\n",
    " 'Perissodactyla':7,\n",
    " 'Primates':8,\n",
    " 'Rodentia':9,\n",
    " 'Scandentia':10,\n",
    " 'Xenarthra':11}\n",
    "\n",
    "FAMILY_MAP = {'Bovidae': 0, # Artiodactyla\n",
    "'Cervidae': 1, # Artiodactyla\n",
    "'Canidae': 2, # Carnivora\n",
    "'Felidae': 3, # Carnivora\n",
    "'Mustelidae': 4, # Carnivora\n",
    "'Giraffidae': 5, # Artiodactyla\n",
    "'Pteropodidae': 6,\n",
    "'Procaviidae': 7,\n",
    "'Cercopithecidae': 8,\n",
    "'Delphinidae': 9,\n",
    "'Hyaenidae': 10,\n",
    "'Ursidae': 11,\n",
    "'Muridae': 12,\n",
    "'Hominidae': 13}\n",
    "\n",
    "REVERSED_FAMILY_MAP = {0: 'Bovidae',\n",
    "                       1: 'Cervidae', \n",
    "                       2: 'Canidae', \n",
    "                       3: 'Felidae', \n",
    "                       4: 'Mustelidae'}\n",
    "\n",
    "CLASSES = ['Bovidae', 'Cervidae', 'Canidae', 'Felidae', 'Mustelidae']\n",
    "\n",
    "def normalize_image(img):\n",
    "    img += abs(img.min())\n",
    "    img /= img.max()\n",
    "    return img\n",
    "\n",
    "from augmentations import Crop\n",
    "        \n",
    "def process_raw_image(datadir, f, order, family, outputdir):\n",
    "    if order.empty:\n",
    "        order = df_info[df_info.Filename.str.fullmatch(f.stem[:f.stem.find('_')])].Order.drop_duplicates()\n",
    "        family = df_info[df_info.Filename.str.fullmatch(f.stem[:f.stem.find('_')])].Family.drop_duplicates()\n",
    "    if order.size != 1:\n",
    "        print(f)\n",
    "        print(order)\n",
    "        return ''\n",
    "    \n",
    "    img = nib.load(f)\n",
    "    img = img.get_fdata()\n",
    "    img = np.nan_to_num(img)\n",
    "    img = normalize_image(img)\n",
    "    \n",
    "    crop = Crop([80,80,32],\"random\")\n",
    "    \n",
    "    annotations = \"\"\n",
    "    for i in range(20):\n",
    "        joblib.dump([crop(img),order], outputdir + f'Processed/{f.stem}_{i}.joblib')\n",
    "        annotations += f'{f.stem}_{i}.joblib,{ORDER_MAP[order.values[0]]},{FAMILY_MAP[family.values[0]]}\\n'\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "def process_raw_images(inputdir='MRI', datadir='data/', outputdir='data/', order=pd.Series(dtype=str), family=pd.Series(dtype=str)):\n",
    "    annotations = 'filename,order,family\\n'\n",
    "    for f in tqdm((Path(datadir)/inputdir).iterdir()):\n",
    "        annotations += process_raw_image(datadir, f, order, family, outputdir)\n",
    "    with open(Path(datadir)/'labels.csv', 'w') as f:\n",
    "        f.write(annotations)\n",
    "        \n",
    "def load_processed(datadir='data/'):\n",
    "    train_loader = []\n",
    "    for f in (Path(datadir)/'Processed').iterdir():\n",
    "        train_loader.append(joblib.load(f))\n",
    "    return train_loader\n",
    "\n",
    "def load_raw(datadir='data/'):\n",
    "    train_loader = []\n",
    "    for f in (Path(datadir)/'MRI').iterdir():\n",
    "        order = df_info[df_info.Filename.str.contains(f.stem[:f.stem.find('_')-1])].Order.drop_duplicates()\n",
    "        if order.size > 1:\n",
    "            print(order)\n",
    "            continue\n",
    "        img = nib.load(f).get_fdata()\n",
    "        train_loader.append([img, order])\n",
    "    return train_loader\n",
    "\n",
    "def trim(arr, mask):\n",
    "    bounding_box = tuple(\n",
    "        slice(np.min(indexes), np.max(indexes) + 1)\n",
    "        for indexes in np.where(mask))\n",
    "    return arr[bounding_box]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95004d3f-a1eb-4514-badc-74ba36c46385",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_raw_images('Resampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe497e-91a3-470f-8e1e-5142663d3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_raw_images('Resampled', datadir='f:/Data/OpenNeuro/ds004114-download/', outputdir='f:/Data/OpenNeuro/', order=pd.Series(['Rodentia']), family=pd.Series(['Muridae']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca330ac1-1f06-4c07-b689-dca53f47be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_raw_images('Resampled', datadir='f:/Data/OpenNeuro/ds004215-download/', outputdir='f:/Data/OpenNeuro/', order=pd.Series(['Primates']), family=pd.Series(['Hominidae']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83761a-4185-4575-a3ec-f512f5d5a50a",
   "metadata": {},
   "source": [
    "### Get Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ccf9a8-b9e4-412a-aee3-bf5f11857495",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for f in Path('data/Resampled/').iterdir():\n",
    "    if f.stem == '.nii':\n",
    "        continue\n",
    "    files.append(f.stem.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b763cbef-1ec0-4052-ae4f-3a8ff9cf9398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_l = pd.read_csv('data/info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181f41ff-1155-4d3d-95f7-70c9057cb9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_l = df_info_l[df_info_l.Filename.isin(files)]\n",
    "df_info_l = df_info_l.drop('Id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9f32a-2d7f-4a17-9308-59348acf9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_l.Family.value_counts().plot(kind='bar')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.savefig('data/data_histogram.jpg', bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eebe2fe-83b6-41b7-9056-0fa0a09ee2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_l.to_csv(\"data/info_short.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7924d9d9-71dc-4252-bc2c-8fca432f78d0",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93998ebd-c9ec-415c-a674-a2cf1f9d44c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_csv('data/labels.csv')\n",
    "df_info = df_info.loc[df_info['family'].isin([0,1,2,3,4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af28acf-a711-413f-bf8e-e079efed1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_info, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174f538a-ea0c-4da3-aec5-d2e909c1d271",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"data/train.csv\", index=False)\n",
    "test.to_csv(\"data/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b2949f-8aba-4ac9-b779-38c70f4a3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_csv('f:/Data/OpenNeuro/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e10dd-0f59-40d7-abb5-cbe381ae8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_info, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb798dc-7b3a-4c51-8f92-5964832876bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"f:/Data/OpenNeuro/train.csv\", index=False)\n",
    "test.to_csv(\"f:/Data/OpenNeuro/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fafa78-dff6-4187-a426-0ebe473da104",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_csv('data/labels.csv')\n",
    "df_info = df_info.loc[df_info['family'].isin([5])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd258b-72bf-4ce5-a714-f18c651c0088",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Print All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcdd0f5-cba0-49c6-9515-eb29256d6964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "for f in Path('data/Processed/').iterdir():\n",
    "    img_arr, _ = joblib.load(f)\n",
    "    imageio.imwrite(f'data/Processed-demo/{f.stem}.jpg', img_arr[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd7a09-95eb-425a-b633-6b040037fb31",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02e295d-459b-4167-9f0b-5d31f0728328",
   "metadata": {},
   "source": [
    "## Train And Validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044a1ac-4700-4e9b-a099-d8cf09b8b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('checkpoint/SupCon_epoch_100.pth')\n",
    "losses = model['losses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be393b3a-6e1a-4da0-8a90-75e24eca6daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 2), dpi=300)\n",
    "plt.plot(range(len(losses['train'])), losses['train'], label=\"train\")\n",
    "plt.plot(range(len(losses['validation'])), losses['validation'], label=\"validation\")\n",
    "plt.legend()\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('losses_SupCon_all', bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6990b9-9df4-4cf8-a3af-6a5ab7d2b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(losses['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3732ddd7-1bc5-41d0-b2f1-6692191832b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses['validation'].index(min(losses['validation']))+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de6baaa-f302-4e74-bde4-76672739244d",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27879285-0f2e-4150-82e3-9f52c069f05c",
   "metadata": {},
   "source": [
    "## Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715722b2-6c61-45ff-9dc9-1021a05ae2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import CustomImageDataset\n",
    "from config import Config, FINE_TUNING\n",
    "\n",
    "config = Config(FINE_TUNING)\n",
    "\n",
    "dataset_test = CustomImageDataset(config, 'data/test.csv', 'data/Processed/', FINE_TUNING)\n",
    "loader_test = DataLoader(dataset_test,\n",
    "                          batch_size=config.batch_size,\n",
    "                          pin_memory=config.pin_mem,\n",
    "                          num_workers=config.num_cpu_workers\n",
    "                          )\n",
    "\n",
    "dataset_unknown = CustomImageDataset(config, 'data/unknown.csv', 'data/Processed/', FINE_TUNING)\n",
    "loader_unknown = DataLoader(dataset_unknown,\n",
    "                          batch_size=config.batch_size,\n",
    "                          pin_memory=config.pin_mem,\n",
    "                          num_workers=config.num_cpu_workers\n",
    "                          )\n",
    "\n",
    "def get_predictions(net, is_encoder=False):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for inputs, labels, paths in loader_test:\n",
    "        if is_encoder:\n",
    "            output = net(inputs).data.cpu().numpy()\n",
    "        else:\n",
    "            output = torch.max(net(inputs), 1)[1].data.cpu().numpy()\n",
    "        y_pred.extend(output) # Save Prediction\n",
    "\n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels) # Save Truth\n",
    "        \n",
    "    return y_pred, y_true\n",
    "\n",
    "def get_embeddings(net, unknown=False):\n",
    "    embed = []\n",
    "    y_true = []\n",
    "    if unknown:\n",
    "        print(\"taking unknown data\")\n",
    "        loader = loader_unknown\n",
    "    else:\n",
    "        print(\"taking test data\")\n",
    "        loader = loader_test\n",
    "            \n",
    "    for inputs, labels, paths in loader:\n",
    "        output = net(inputs, return_hidden=True).data.cpu().numpy()\n",
    "        embed.extend(output) # Save Prediction\n",
    "\n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels) # Save Truth\n",
    "        \n",
    "    return embed, y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a0dd18-d045-45e7-90b8-6090b58a06a7",
   "metadata": {},
   "source": [
    "## Load the classifier and plot a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab472009-fe3c-4d14-8644-5c6fadf049c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.load('checkpoint/fine_tune_epoch_199_all.pth')\n",
    "net = densenet121(mode=\"classifier\", drop_rate=0.0, num_classes=12)\n",
    "net = torch.nn.DataParallel(net).to('cuda')\n",
    "net.load_state_dict(model['model'])\n",
    "y_pred, y_true = get_predictions(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f999275-cfeb-47bb-8fe8-318a47cdcae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES_ALL = ['Bov', 'Cer', 'Can', 'Fel', 'Mus', 'Gir', 'Pte', 'Pro', 'Cer', 'Del', 'Hya', 'Urs']\n",
    "ConfusionMatrixDisplay.from_predictions(y_true, y_pred, display_labels=CLASSES_ALL, cmap='Blues', values_format='.0%', normalize='true')\n",
    "plt.savefig('confusion_matrix_SupCon_all_98.png', bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770f06ac-464c-4ff6-81c1-ea55ca143b00",
   "metadata": {},
   "source": [
    "# Latent Space Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e5288-7900-40d3-aa77-2f5634efffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('checkpoint/fine_tune_epoch_46_5_classes_supcon.pth')\n",
    "net = densenet121(mode=\"classifier\", drop_rate=0.0, num_classes=5)\n",
    "net = torch.nn.DataParallel(net).to('cuda')\n",
    "net.load_state_dict(model['model'])\n",
    "embed, y_true = get_embeddings(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f31db1-403b-4f62-9a14-016479197795",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed, y_true = get_embeddings(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7537e46c-af62-4ab6-a31f-9d43b0aa8b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, random_state=123, n_iter=10000)\n",
    "z = tsne.fit_transform(embed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3513a79e-9866-4804-8b76-9af333f1d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.get_cmap('Set1').copy()\n",
    "cmap2 = plt.cm.get_cmap('Dark2').copy()\n",
    "cmap = matplotlib.colors.ListedColormap(cmap.colors[:5] + cmap2.colors[:7])\n",
    "scatter = plt.scatter(x=z[:,0], y=z[:,1], c=y_true, cmap=cmap)\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=CLASSES_ALL)\n",
    "plt.savefig('latent_space.png', bbox_inches = 'tight', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
